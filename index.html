<!DOCTYPE html>
<html lang="en">
<head>
  <!--
    MIT License

    Copyright (c) 2025 NQR

    Permission is hereby granted, free of charge, to any person obtaining a copy
    of this software and associated documentation files (the "Software"), to deal
    in the Software without restriction, including without limitation the rights
    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
    copies of the Software, and to permit persons to whom the Software is
    furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in all
    copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
    SOFTWARE.
  -->
  <!-- Favicons (browser tabs, bookmarks) -->
  <link rel="icon" type="image/png" sizes="32x32" href="assets/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="assets/images/favicon-16x16.png">
    
  <!-- iOS & iPadOS (home screen icon when ï¿½Add to Home Screenï¿½) -->
  <link rel="apple-touch-icon" sizes="180x180" href="assets/images/apple-touch-icon-180x180.png">
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Apoculus</title>

  <!-- ONNX Runtime Web for AI depth prediction -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.2/dist/ort.webgpu.min.js"></script>

  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    :root { color-scheme:dark; }

    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: #04070a;
      color: #d7e8ff;
      overflow: hidden;
      height: 100vh;
    }

    .container {
      display: flex;
      height: 100vh;
    }

    /* Control Panel */
    .control-panel {
      width: 320px;
      background: linear-gradient(180deg, #0a0f14 0%, #04070a 100%);
      border-right: 1px solid rgba(93, 225, 255, 0.2);
      overflow-y: auto;
      overflow-x: hidden;
      padding: 20px;
    }

    .control-panel::-webkit-scrollbar {
      width: 8px;
    }

    .control-panel::-webkit-scrollbar-track {
      background: rgba(0, 0, 0, 0.2);
    }

    .control-panel::-webkit-scrollbar-thumb {
      background: rgba(93, 225, 255, 0.3);
      border-radius: 4px;
    }

    .control-panel::-webkit-scrollbar-thumb:hover {
      background: rgba(93, 225, 255, 0.5);
    }

    header {
      margin-bottom: 20px;
      padding-bottom: 15px;
      border-bottom: 2px solid rgba(93, 225, 255, 0.2);
    }

    h1 {
      font-size: 1.8rem;
      color: #5de1ff;
      margin-bottom: 5px;
      text-shadow: 0 0 10px rgba(93, 225, 255, 0.3);
      justify-content: center;
      align-items: center;
      display: flex;
    }

    .subtitle {
      font-size: 0.85rem;
      color: #97f3d2;
      opacity: 0.9;
      justify-content: center;
      align-items: center;
      display: flex;
    }

    .section {
      margin-bottom: 25px;
    }

    .section-title {
      font-size: 0.9rem;
      color: #00d4ff;
      margin-bottom: 12px;
      text-transform: uppercase;
      letter-spacing: 0.5px;
      font-weight: bold;
    }

    .control-group {
      margin-bottom: 15px;
    }

    .control-label {
      display: block;
      font-size: 0.85rem;
      color: #97f3d2;
      margin-bottom: 6px;
    }
    
    li {margin-left: 20px; padding: 0px; margin-top: 0px; margin-bottom: 0px;}

    input[type="text"],
    input[type="number"],
    select,
    textarea {
      width: 100%;
      padding: 8px 10px;
      background: rgba(0, 0, 0, 0.3);
      border: 1px solid rgba(93, 225, 255, 0.3);
      border-radius: 4px;
      color: #d7e8ff;
      font-size: 0.9rem;
      font-family: inherit;
    }

    textarea {
      resize: vertical;
      min-height: 60px;
      font-family: 'Segoe UI', sans-serif;
    }

    select, option {
      color: #d7e8ff;
      background-color: #04070a;
    }

    option:checked,
    option:hover {
      color: #d7e8ff;
      background-color: rgba(50, 50, 50, 0.3);
    }

    input[type="text"]:focus,
    input[type="number"]:focus,
    select:focus,
    textarea:focus {
      outline: none;
      border-color: #5de1ff;
      box-shadow: 0 0 8px rgba(93, 225, 255, 0.3);
    }

    input[type="range"] {
      width: 100%;
      height: 4px;
      background: rgba(93, 225, 255, 0.2);
      border-radius: 2px;
      outline: none;
      -webkit-appearance: none;
      appearance: none;
    }

    input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      width: 16px;
      height: 16px;
      background: #5de1ff;
      border-radius: 50%;
      cursor: pointer;
      box-shadow: 0 0 8px rgba(93, 225, 255, 0.5);
    }

    input[type="range"]::-moz-range-thumb {
      width: 16px;
      height: 16px;
      background: #5de1ff;
      border-radius: 50%;
      cursor: pointer;
      border: none;
      box-shadow: 0 0 8px rgba(93, 225, 255, 0.5);
    }

    .range-value {
      display: inline-block;
      margin-left: 10px;
      font-size: 0.85rem;
      color: #5de1ff;
      min-width: 50px;
      text-align: right;
    }

    .range-container {
      display: flex;
      align-items: center;
      gap: 10px;
    }

    .range-container input[type="range"] {
      flex: 1;
    }

    button {
      padding: 10px 16px;
      background: linear-gradient(135deg, #5de1ff 0%, #00ffaa 100%);
      border: none;
      border-radius: 4px;
      color: #04070a;
      font-size: 0.9rem;
      font-weight: bold;
      cursor: pointer;
      transition: transform 0.2s, box-shadow 0.2s;
      box-shadow: 0 4px 12px rgba(93, 225, 255, 0.3);
      width: 100%;
    }

    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 6px 16px rgba(93, 225, 255, 0.5);
    }

    button:active {
      transform: translateY(0);
    }

    .button-group {
      display: flex;
      gap: 8px;
      margin-bottom: 10px;
    }

    .button-group button {
      flex: 1;
    }

    .secondary-btn {
      background: linear-gradient(135deg, rgba(93, 225, 255, 0.2) 0%, rgba(0, 255, 170, 0.2) 100%);
      color: #5de1ff;
    }

    .danger-btn {
      background: linear-gradient(135deg, rgba(255, 93, 93, 0.3) 0%, rgba(255, 0, 85, 0.3) 100%);
      color: #ff5d5d;
    }

    input[type="file"] {
      display: none;
    }

    .file-label {
      display: block;
      padding: 10px 16px;
      background: linear-gradient(135deg, rgba(93, 225, 255, 0.2) 0%, rgba(0, 255, 170, 0.2) 100%);
      border: 1px solid rgba(93, 225, 255, 0.3);
      border-radius: 4px;
      color: #5de1ff;
      font-size: 0.9rem;
      font-weight: bold;
      cursor: pointer;
      text-align: center;
      transition: all 0.2s;
    }

    .file-label:hover {
      background: linear-gradient(135deg, rgba(93, 225, 255, 0.3) 0%, rgba(0, 255, 170, 0.3) 100%);
      border-color: #5de1ff;
    }

    .info-hint {
      font-size: 0.75rem;
      color: rgba(151, 243, 210, 0.7);
      margin-top: 4px;
    }

    /* Layers */
    .layer-list {
      max-height: 300px;
      overflow-y: auto;
      margin-bottom: 10px;
      border: 1px solid rgba(93, 225, 255, 0.2);
      border-radius: 4px;
      background: rgba(0, 0, 0, 0.2);
    }

    .layer-item {
      padding: 10px;
      border-bottom: 1px solid rgba(93, 225, 255, 0.1);
      cursor: pointer;
      transition: background 0.2s;
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .layer-item:hover {
      background: rgba(93, 225, 255, 0.05);
    }

    .layer-item.active {
      background: rgba(93, 225, 255, 0.15);
      border-left: 3px solid #5de1ff;
    }

    .layer-info {
      width: 100%;
    }

    .layer-name {
      font-size: 0.9rem;
      color: #d7e8ff;
      font-weight: bold;
      margin-bottom: 2px;
    }

    .layer-details {
      font-size: 0.75rem;
      color: rgba(151, 243, 210, 0.7);
    }

    .layer-delete {
      width: 100%;
      padding: 6px 10px;
      background: rgba(255, 93, 93, 0.2);
      border: 1px solid rgba(255, 93, 93, 0.3);
      border-radius: 3px;
      color: #ff5d5d;
      font-size: 0.8rem;
      cursor: pointer;
      transition: all 0.2s;
      text-align: center;
    }

    .layer-delete:hover {
      background: rgba(255, 93, 93, 0.3);
    }

    /* Preview Panel */
    .preview-panel {
      flex: 1;
      display: flex;
      flex-direction: column;
      background: #04070a;
      position: relative;
    }

    .preview-header {
      padding: 15px 20px;
      background: rgba(10, 15, 20, 0.8);
      border-bottom: 1px solid rgba(93, 225, 255, 0.2);
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .preview-title {
      font-size: 1.1rem;
      color: #5de1ff;
    }

    .preview-actions {
      display: flex;
      gap: 10px;
    }

    .preview-actions button {
      width: auto;
      padding: 8px 16px;
    }

    .preview-container {
      flex: 1;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 20px;
      overflow: auto;
    }

    #previewCanvas {
      max-width: 100%;
      max-height: 100%;
      border: 1px solid rgba(93, 225, 255, 0.3);
      box-shadow: 0 0 20px rgba(93, 225, 255, 0.2);
      background: #000;
    }

    .help-text {
      text-align: center;
      color: rgba(151, 243, 210, 0.5);
      font-size: 0.9rem;
      padding: 20px;
    }

    @media (max-width: 768px) {
      .container {
        flex-direction: column;
      }

      .control-panel {
        width: 100%;
        height: 50vh;
        border-right: none;
        border-bottom: 1px solid rgba(93, 225, 255, 0.2);
      }

      .preview-panel {
        height: 50vh;
      }
    }

    /* License modal styles */
    .license-footer {
      margin-top: 30px;
      margin-bottom: 20px;
      padding: 10px 8px;
      font-size: 0.68rem;
      color: #a9a9b2;
      opacity: 0.7;
      cursor: pointer;
      transition: opacity 0.15s ease;
      text-align: center;
    }

    .license-footer:hover { opacity: 1; }

    .license-overlay {
      display: none;
      position: fixed;
      inset: 0;
      background: rgba(0,0,0,0.7);
      z-index: 999;
    }

    .license-modal {
      display: none;
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: #0f0f16;
      border: 2px solid rgba(93, 225, 255, 0.35);
      border-radius: 12px;
      padding: 20px;
      max-width: 520px;
      width: 90%;
      max-height: 80vh;
      overflow-y: auto;
      box-shadow: 0 20px 60px rgba(0,0,0,.6);
      z-index: 1000;
      text-align: center;
    }

    .license-modal.show,
    .license-overlay.show {
      display: block;
    }

    .license-modal-header {
      position: relative;
      display: flex;
      justify-content: center;
      align-items: center;
      padding-right: 32px;
      gap: 12px;
    }

    .license-modal-title {
      font-size: 18px;
      color: #5de1ff;
      margin-bottom: 15px;
    }

    .license-modal-text {
      font-size: 12px;
      line-height: 1.6;
      color: #b0b0b0;
      text-align: left;
      white-space: pre-wrap;
    }

    .license-close {
      position: absolute;
      top: 0;
      right: 0;
      width: 28px;
      height: 28px;
      border-radius: 50%;
      background: rgba(255,0,0,0.15);
      border: 1px solid rgba(255,0,0,0.3);
      color: #ff5555;
      font-size: 18px;
      line-height: 1;
      cursor: pointer;
      transition: all 0.2s ease;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .license-close:hover {
      background: rgba(255,0,0,0.3);
      border-color: #ff5555;
    }
  </style>
</head>
<body>
  <div class="container">
    <!-- Control Panel -->
    <div class="control-panel">
      <header>
        <img src="assets/images/logo.png" alt="Apoculus Logo" onerror="this.style.display='none'" style="display:block; margin-left:auto; margin-right:auto; width:50%;">
        <h1>Apoculus</h1>
        <p class="subtitle">3D Image Generator</p>
      </header>

      <!-- Add Layer -->
      <div class="section">
        <div class="section-title">
          Add Layer
          <span id="imageDepthHelpLink" style="margin-left: 10px; font-size: 0.75rem; color: #5de1ff; cursor: pointer; opacity: 0.8;">Help</span>
        </div>
        <div class="button-group">
          <button id="addTextBtn">+ Text</button>
          <button id="addImageBtn" class="secondary-btn">+ Image</button>
        </div>
        <input type="file" id="imageFileInput" accept="image/*">
      </div>

      <!-- Layers -->
      <div class="section">
        <div class="section-title">Layers</div>
        <div class="layer-list" id="layerList">
          <div class="help-text" style="font-size: 0.85rem; padding: 15px;">
            No layers yet. Add text or an image to begin.
          </div>
        </div>
      </div>

      <!-- Layer Settings -->
      <div class="section" id="layerSettings" style="display: none;">
        <div class="section-title">Layer Settings</div>

        <!-- Text Content -->
        <div class="control-group" id="textContentGroup" style="display: none;">
          <label class="control-label">Text</label>
          <textarea id="layerText" placeholder="Enter text..."></textarea>
        </div>

        <!-- Font Selection -->
        <div class="control-group" id="fontGroup" style="display: none;">
          <label class="control-label">Font</label>
          <select id="layerFont">
            <option value="'Arial Black', sans-serif">Arial Black</option>
            <option value="'Impact', sans-serif">Impact</option>
            <option value="'Trebuchet MS', sans-serif">Trebuchet MS</option>
            <option value="'Verdana', sans-serif">Verdana</option>
            <option value="'Tahoma', sans-serif">Tahoma</option>
            <option value="custom">Upload Custom Font...</option>
          </select>
          <input type="file" id="customFontInput" accept=".ttf,.otf,.woff,.woff2" style="margin-top: 8px;">
        </div>

        <!-- Size -->
        <div class="control-group">
          <label class="control-label">Size</label>
          <div class="range-container">
            <input type="range" id="layerSize" min="20" max="400" value="100">
            <span class="range-value" id="layerSizeValue">100</span>
          </div>
        </div>

        <!-- Depth -->
        <div class="control-group">
          <label class="control-label">Depth Level</label>
          <div class="range-container">
            <input type="range" id="layerDepth" min="0" max="100" value="20">
            <span class="range-value" id="layerDepthValue">20</span>
          </div>
          <div class="info-hint">Higher = closer to you</div>
        </div>

        <!-- Rotation -->
        <div class="control-group">
          <label class="control-label">Rotation</label>
          <div class="range-container">
            <input type="range" id="layerRotation" min="-180" max="180" value="0">
            <span class="range-value" id="layerRotationValue">0Â°</span>
          </div>
        </div>

        <!-- Position X -->
        <div class="control-group">
          <label class="control-label">Horizontal Position</label>
          <div class="range-container">
            <input type="range" id="layerX" min="0" max="1000" value="500">
            <span class="range-value" id="layerXValue">500</span>
          </div>
        </div>

        <!-- Position Y -->
        <div class="control-group">
          <label class="control-label">Vertical Position</label>
          <div class="range-container">
            <input type="range" id="layerY" min="0" max="1000" value="500">
            <span class="range-value" id="layerYValue">500</span>
          </div>
        </div>

        <!-- Depth Algorithm (for images) -->
        <div class="control-group" id="depthAlgorithmGroup" style="display: none;">
          <label class="control-label">Depth Algorithm</label>
          <select id="layerDepthAlgorithm">
            <option value="depth-anything-v2">Depth Anything V2 (AI)</option>
            <option value="direct">Direct Grayscale Mapping</option>
            <option value="retinex">Shadow-Aware (Retinex-inspired)</option>
          </select>
          <div class="info-hint">AI depth prediction works best for photos and complex scenes</div>
        </div>

        <!-- Retinex Radius (for shadow-aware algorithm) -->
        <div class="control-group" id="retinexRadiusGroup" style="display: none;">
          <label class="control-label">Shadow Detection Radius</label>
          <div class="range-container">
            <input type="range" id="layerRetinexRadius" min="16" max="64" value="32" step="4">
            <span class="range-value" id="layerRetinexRadiusValue">32px</span>
          </div>
          <div class="info-hint">Larger radius = smoother illumination estimation</div>
        </div>

        <!-- Depth Gamma (for images) -->
        <div class="control-group" id="depthGammaGroup" style="display: none;">
          <label class="control-label">Depth Gamma</label>
          <div class="range-container">
            <input type="range" id="layerDepthGamma" min="0.6" max="1.4" value="1.0" step="0.05">
            <span class="range-value" id="layerDepthGammaValue">1.0</span>
          </div>
          <div class="info-hint">Adjust midtone depth distribution (lower = flatter, higher = steeper)</div>
        </div>

        <!-- Invert Depth (for images) -->
        <div class="control-group" id="invertDepthGroup" style="display: none;">
          <label class="control-label">
            <input type="checkbox" id="invertDepth" style="width: auto; margin-right: 8px;">
            Invert Depth
          </label>
          <div class="info-hint">When checked, black=foreground, white=background (transparent always stays background)</div>
        </div>
      </div>

      <!-- Global Settings -->
      <div class="section">
        <div class="section-title">Image Settings</div>

        <!-- Pattern Density -->
        <div class="control-group">
          <label class="control-label">Pattern Density</label>
          <div class="range-container">
            <input type="range" id="patternDensity" min="2" max="8" value="4" step="1">
            <span class="range-value" id="patternDensityValue">4</span>
          </div>
          <div class="info-hint">Dots per tile</div>
        </div>

        <!-- Strip Width -->
        <div class="control-group">
          <label class="control-label">Pattern Width</label>
          <div class="range-container">
            <input type="range" id="stripWidth" min="47" max="97" value="73" step="1">
            <span class="range-value" id="stripWidthValue">73px</span>
          </div>
        </div>

        <!-- Depth Scale -->
        <div class="control-group">
          <label class="control-label">3D Effect Strength</label>
          <div class="range-container">
            <input type="range" id="depthScale" min="0.3" max="1.5" value="0.8" step="0.1">
            <span class="range-value" id="depthScaleValue">0.8</span>
          </div>
        </div>

        <!-- Output Size -->
        <div class="control-group">
          <label class="control-label">Output Width</label>
          <div class="range-container">
            <input type="range" id="outputWidth" min="800" max="2000" value="1200" step="100">
            <span class="range-value" id="outputWidthValue">1200px</span>
          </div>
        </div>

        <!-- Color Scheme -->
        <div class="control-group">
          <label class="control-label">Color Scheme</label>
          <select id="colorScheme">
            <option value="grayscale">Grayscale</option>
            <option value="color">Random Colors</option>
            <option value="cyan">Cyan Dots</option>
            <option value="magenta">Magenta Dots</option>
            <option value="green">Green Dots</option>
            <option value="amber">Amber Dots</option>
            <option value="rainbow">Rainbow</option>
            <option value="neon">Neon Mix</option>
            <option value="fire">Fire</option>
            <option value="ice">Ice</option>
            <option value="forest">Forest</option>
            <option value="sunset">Sunset</option>
            <option value="ocean">Ocean</option>
            <option value="matrix">Matrix Green</option>
            <option value="vaporwave">Vaporwave</option>
            <option value="synthwave">Synthwave</option>
          </select>
        </div>
      </div>

      <!-- Export -->
      <div class="section">
        <button id="downloadBtn">â¬‡ Download Image</button>
      </div>

      <div class="license-footer" id="licenseFooter">
        MIT License Â© 2025 NQR &middot; Click to view
      </div>
    </div>

    <!-- Preview Panel -->
    <div class="preview-panel">
      <div class="preview-header">
        <div class="preview-title">Preview</div>
        <div class="preview-actions">
          <button id="regenerateBtn">ðŸ”„ Regenerate</button>
        </div>
      </div>
      <div class="preview-container">
        <canvas id="previewCanvas" width="1200" height="800"></canvas>
      </div>
    </div>
  </div>

  <!-- License Modal -->
  <div class="license-overlay" id="licenseOverlay"></div>
  <div class="license-modal" id="licenseModal">
    <div class="license-modal-header">
      <h2 class="license-modal-title">MIT License</h2>
      <div class="license-close" id="licenseClose">Ã—</div>
    </div>
    <div class="license-modal-text">Copyright (c) 2025 NQR

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
    </div>
  </div>

  <!-- Image Depth Help Modal -->
  <div class="license-overlay" id="depthHelpOverlay"></div>
  <div class="license-modal" id="depthHelpModal" style="max-width: 700px; max-height: 85vh;">
    <div class="license-modal-header">
      <h2 class="license-modal-title">Creating Depth Maps for Images</h2>
      <div class="license-close" id="depthHelpClose">Ã—</div>
    </div>
    <div class="license-modal-text" style="text-align: left; line-height: 1.6; white-space: normal;">
      <p style="margin: 0 0 10px 0; color: #d7e8ff; font-size: 13px;">There are several ways to prepare images for depth mapping in Apoculus. Choose the method that works best for your workflow:</p>

      <h3 style="margin: 10px 0 5px 0; color: #5de1ff; font-size: 14px; font-weight: bold;">ðŸ¤– AI-Powered (Easiest)</h3>
      <p style="margin: 0 0 3px 0;"><strong style="color: #00ffaa;">Depth Anything V2 (Built-in)</strong></p>
      <p style="margin: 0 0 5px 0;">Upload any photo and let the AI predict depth automatically. Works great for portraits, landscapes, and complex scenes. Just select "Depth Anything V2 (AI)" from the Depth Algorithm dropdown.</p>
      <p style="margin: 0 0 10px 0; font-size: 12px; opacity: 0.8;">âœ“ Best for photos and natural scenes<br>âœ“ No preparation needed<br>âœ“ Model loads automatically on first use (~97MB)</p>

      <h3 style="margin: 10px 0 5px 0; color: #5de1ff; font-size: 14px; font-weight: bold;">ðŸŽ¨ Manual Grayscale Depth Maps</h3>
      <p style="margin: 0 0 3px 0;"><strong style="color: #00ffaa;">Simple Silhouettes</strong></p>
      <p style="margin: 0 0 8px 0;">Create a grayscale image where white = foreground (near) and black = background (far). Works great for logos, icons, and simple graphics.</p>

      <p style="margin: 0 0 3px 0;"><strong style="color: #00ffaa;">Layered Depth with GIMP/Photoshop</strong></p>
      <p style="margin: 0 0 3px 0;">Create complex multi-depth scenes:</p>
      <ol style="margin: 0 0 8px 20px; padding: 0;">
        <li style="margin-bottom: 2px;">Separate your image into layers (foreground, midground, background)</li>
        <li style="margin-bottom: 2px;">Create silhouettes of each layer</li>
        <li style="margin-bottom: 2px;">Assign different grayscale values:
          <ul style="margin: 2px 0 0 15px;">
            <li>Closest objects: White (255)</li>
            <li>Middle distance: Mid-gray (128)</li>
            <li>Far background: Dark gray (64)</li>
            <li>Sky/background: Black (0)</li>
          </ul>
        </li>
        <li style="margin-bottom: 2px;">Flatten to a single grayscale image</li>
        <li>Optional: Use Gaussian blur to smooth transitions between layers</li>
      </ol>

      <p style="margin: 0 0 3px 0;"><strong style="color: #00ffaa;">3D Software Export</strong></p>
      <p style="margin: 0 0 10px 0;">If you're working with 3D models in Blender, Maya, or similar tools, you can render a depth pass (Z-depth) and export it as a grayscale image. This gives you precise control over depth based on actual 3D geometry.</p>

      <h3 style="margin: 10px 0 5px 0; color: #5de1ff; font-size: 14px; font-weight: bold;">ðŸ“± Mobile Apps & Web Tools</h3>
      <p style="margin: 0 0 3px 0;"><strong style="color: #00ffaa;">Mobile Apps</strong></p>
      <p style="margin: 0 0 8px 0;"><strong>DepthMaker</strong> - iOS/Android app that generates depth maps from photos using portrait mode or AI</p>

      <p style="margin: 0 0 3px 0;"><strong style="color: #00ffaa;">Web-Based Tools</strong></p>
      <p style="margin: 0 0 2px 0;"><strong>Depth Map Extractor</strong> - Extract depth data from images with depth information</p>
      <p style="margin: 0 0 2px 0;"><strong>Depthy</strong> - Create depth maps from photos with interactive painting tools</p>
      <p style="margin: 0 0 10px 0;"><strong>3D Photo Inpainting</strong> - AI-based depth estimation from single photos</p>

      <h3 style="margin: 10px 0 5px 0; color: #5de1ff; font-size: 14px; font-weight: bold;">ðŸ’¡ Tips for Best Results</h3>
      <ul style="margin: 0 0 10px 20px; padding: 0;">
        <li style="margin-bottom: 2px;"><strong>High Contrast:</strong> Images with clear brightness differences produce better 3D effects</li>
        <li style="margin-bottom: 2px;"><strong>Smooth Gradients:</strong> Use Gaussian blur on depth transitions to avoid "sparkle" artifacts</li>
        <li style="margin-bottom: 2px;"><strong>PNG Transparency:</strong> Transparent backgrounds automatically stay at depth 0 (far)</li>
        <li style="margin-bottom: 2px;"><strong>Depth Gamma:</strong> Adjust 0.6-1.4 to control how midtones map to depth</li>
        <li style="margin-bottom: 2px;"><strong>Invert Depth:</strong> Use for white-on-black images or reversed depth perception</li>
        <li><strong>Shadow-Aware Algorithm:</strong> Use for photos with strong shadows or uneven lighting</li>
      </ul>

      <h3 style="margin: 10px 0 5px 0; color: #5de1ff; font-size: 14px; font-weight: bold;">ðŸŽ¯ Quick Workflow Recommendations</h3>
      <p style="margin: 0 0 2px 0;"><strong>For photos:</strong> Use Depth Anything V2 (AI)</p>
      <p style="margin: 0 0 2px 0;"><strong>For logos/graphics:</strong> Create simple grayscale silhouettes</p>
      <p style="margin: 0 0 2px 0;"><strong>For layered scenes:</strong> Use GIMP/Photoshop with multiple gray levels</p>
      <p style="margin: 0 0 2px 0;"><strong>For 3D projects:</strong> Export Z-depth pass from your 3D software</p>
      <p style="margin: 0 0 10px 0;"><strong>For mobile workflow:</strong> Use DepthMaker app, then upload here</p>

      <p style="margin: 10px 0 0 0; padding: 10px; background: rgba(93, 225, 255, 0.1); border-left: 3px solid #5de1ff; font-size: 12px; color: #d7e8ff;">
        <strong>Remember:</strong> Depth maps are just grayscale images where brightness = distance from viewer. White = close, black = far. Everything else is creative freedom!
      </p>
    </div>
  </div>

  <script>
    // App State
    const state = {
      layers: [],
      activeLayerId: null,
      customFonts: new Map(),
      settings: {
        patternDensity: 4,
        stripWidth: 73,
        depthScale: 0.8,
        outputWidth: 1200,
        outputHeight: 800,
        colorScheme: 'grayscale'
      }
    };

    let nextLayerId = 1;

    // Cache for AI depth predictions (avoid re-running model on parameter changes)
    const depthCache = new Map(); // layerId -> { rawDepth: ImageData, algorithm: string }

    // --- Depth Anything V2 (AI depth prediction) ---
    // Based on "Depth Anything V2" by DepthAnything team
    // Model: https://github.com/DepthAnything/Depth-Anything-V2
    // ONNX Model: https://huggingface.co/onnx-community/depth-anything-v2-small
    // ONNX conversion by Hugging Face ONNX Community
    // License: Apache 2.0 (see LICENSES-THIRD-PARTY.md)
    let depthModel = null;
    let depthModelLoading = false;

    // ImageNet normalization constants
    const IMAGENET_MEAN = [0.485, 0.456, 0.406];
    const IMAGENET_STD = [0.229, 0.224, 0.225];

    // Load the Depth Anything V2 model
    async function loadDepthModel() {
      if (depthModel) return depthModel;
      if (depthModelLoading) {
        // Wait for ongoing load
        while (depthModelLoading) {
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        return depthModel;
      }

      depthModelLoading = true;
      try {
        // Configure ONNX Runtime to use WebGPU with WASM fallback
        const session = await ort.InferenceSession.create(
          'models/depth-anything-v2-small-518.onnx',
          { executionProviders: ['webgpu', 'wasm'] }
        );
        depthModel = session;
        console.log('Depth Anything V2 model loaded successfully');
        return depthModel;
      } catch (error) {
        console.error('Failed to load Depth Anything V2 model:', error);
        throw error;
      } finally {
        depthModelLoading = false;
      }
    }

    // Resize and letterbox image to 518x518 preserving aspect ratio
    function drawToSquare518(img) {
      const targetSize = 518;
      const canvas = document.createElement('canvas');
      canvas.width = targetSize;
      canvas.height = targetSize;
      const ctx = canvas.getContext('2d');

      // Fill with black (will be letterbox bars)
      ctx.fillStyle = '#000000';
      ctx.fillRect(0, 0, targetSize, targetSize);

      // Calculate scaling to fit within 518x518 while preserving aspect ratio
      const scale = Math.min(targetSize / img.width, targetSize / img.height);
      const scaledWidth = Math.round(img.width * scale);
      const scaledHeight = Math.round(img.height * scale);

      // Center the image
      const x = Math.floor((targetSize - scaledWidth) / 2);
      const y = Math.floor((targetSize - scaledHeight) / 2);

      ctx.drawImage(img, x, y, scaledWidth, scaledHeight);

      return { canvas, scaledWidth, scaledHeight, offsetX: x, offsetY: y };
    }

    // Build NCHW float32 tensor with ImageNet normalization (optimized)
    function makeInputTensor(canvas) {
      const ctx = canvas.getContext('2d');
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const { data, width, height } = imageData;

      // Create NCHW tensor (1, 3, 518, 518)
      const tensorData = new Float32Array(1 * 3 * height * width);
      const pixelCount = height * width;

      // Pre-calculate normalization constants
      const r_scale = 1.0 / (255.0 * IMAGENET_STD[0]);
      const g_scale = 1.0 / (255.0 * IMAGENET_STD[1]);
      const b_scale = 1.0 / (255.0 * IMAGENET_STD[2]);
      const r_mean_norm = IMAGENET_MEAN[0] / IMAGENET_STD[0];
      const g_mean_norm = IMAGENET_MEAN[1] / IMAGENET_STD[1];
      const b_mean_norm = IMAGENET_MEAN[2] / IMAGENET_STD[2];

      // Convert RGBA to normalized RGB channels (NCHW format)
      // Optimized: single pass through pixel data, vectorized operations
      const rOffset = 0;
      const gOffset = pixelCount;
      const bOffset = pixelCount * 2;

      for (let i = 0; i < pixelCount; i++) {
        const pixelOffset = i * 4;
        tensorData[rOffset + i] = data[pixelOffset] * r_scale - r_mean_norm;
        tensorData[gOffset + i] = data[pixelOffset + 1] * g_scale - g_mean_norm;
        tensorData[bOffset + i] = data[pixelOffset + 2] * b_scale - b_mean_norm;
      }

      return new ort.Tensor('float32', tensorData, [1, 3, height, width]);
    }

    // Run the model and return Float32 depth array (HxW)
    async function predictDepthFloat(img) {
      const model = await loadDepthModel();

      // Prepare input
      const { canvas, scaledWidth, scaledHeight, offsetX, offsetY } = drawToSquare518(img);
      const inputTensor = makeInputTensor(canvas);

      // Run inference
      const feeds = { pixel_values: inputTensor };
      const results = await model.run(feeds);

      // Get depth output (should be [1, 518, 518])
      const depthTensor = results[Object.keys(results)[0]];
      const depthData = depthTensor.data;
      const tensorHeight = depthTensor.dims[1];
      const tensorWidth = depthTensor.dims[2];

      // Extract the region corresponding to the actual image (remove letterbox)
      // Optimized: use row-based copying instead of pixel-by-pixel
      const depthArray = new Float32Array(scaledHeight * scaledWidth);

      for (let y = 0; y < scaledHeight; y++) {
        const srcRowStart = (offsetY + y) * tensorWidth + offsetX;
        const dstRowStart = y * scaledWidth;
        // Copy entire row at once (much faster than pixel-by-pixel)
        for (let x = 0; x < scaledWidth; x++) {
          depthArray[dstRowStart + x] = depthData[srcRowStart + x];
        }
      }

      return {
        data: depthArray,
        width: scaledWidth,
        height: scaledHeight
      };
    }

    // Fast histogram-based percentile calculation (O(n) instead of O(n log n) sort)
    function findPercentilesHistogram(data, p2, p98) {
      const len = data.length;

      // Find min/max for histogram range
      let min = Infinity, max = -Infinity;
      for (let i = 0; i < len; i++) {
        const v = data[i];
        if (v < min) min = v;
        if (v > max) max = v;
      }

      // Create histogram with 1024 buckets (good balance of accuracy vs speed)
      const numBuckets = 1024;
      const histogram = new Uint32Array(numBuckets);
      const range = max - min || 1;
      const bucketSize = range / numBuckets;

      // Build histogram
      for (let i = 0; i < len; i++) {
        const bucketIdx = Math.min(numBuckets - 1, Math.floor((data[i] - min) / bucketSize));
        histogram[bucketIdx]++;
      }

      // Find percentile values from histogram
      const p2_target = Math.floor(len * p2);
      const p98_target = Math.floor(len * p98);

      let count = 0;
      let p2_val = min, p98_val = max;
      let foundP2 = false, foundP98 = false;

      for (let i = 0; i < numBuckets; i++) {
        count += histogram[i];

        if (!foundP2 && count >= p2_target) {
          p2_val = min + (i + 0.5) * bucketSize;
          foundP2 = true;
        }

        if (!foundP98 && count >= p98_target) {
          p98_val = min + (i + 0.5) * bucketSize;
          foundP98 = true;
          break;
        }
      }

      return { min: p2_val, max: p98_val };
    }

    // Convert depth to U8 using robust min/max (2-98 percentiles), invert so white=near
    function depthToU8(depthFloat, width, height) {
      const data = depthFloat.data;
      const len = data.length;

      // Fast histogram-based percentile calculation (O(n) instead of O(n log n))
      const { min: minVal, max: maxVal } = findPercentilesHistogram(data, 0.02, 0.98);
      const range = maxVal - minVal || 1;
      const invRange = 1.0 / range;

      // Convert to U8, inverting so white=near (closer), black=far
      // Optimized: pre-calculate constants, minimize operations per pixel
      const u8Data = new Uint8ClampedArray(width * height * 4);

      for (let i = 0; i < len; i++) {
        // Normalize and clamp in one operation
        let normalized = (data[i] - minVal) * invRange;
        normalized = normalized < 0 ? 0 : normalized > 1 ? 1 : normalized;

        // Invert and convert: (1 - normalized) * 255
        const value = ((1 - normalized) * 255) | 0; // Bitwise OR for fast floor

        const idx = i * 4;
        u8Data[idx] = value;
        u8Data[idx + 1] = value;
        u8Data[idx + 2] = value;
        u8Data[idx + 3] = 255;
      }

      return u8Data;
    }

    // Apply Depth Anything V2 to get RAW depth map (normalized grayscale 0-255)
    // Returns normalized depth without LUT application - LUT applied later for fast parameter changes
    async function applyDepthAnythingV2Raw(img) {
      const startTime = performance.now();

      // Get depth prediction
      const depthFloat = await predictDepthFloat(img);
      const inferenceTime = performance.now();
      console.log(`Depth inference: ${(inferenceTime - startTime).toFixed(1)}ms`);

      // Convert to U8 grayscale (normalized, inverted depth)
      const u8Data = depthToU8(depthFloat, depthFloat.width, depthFloat.height);
      const convertTime = performance.now();
      console.log(`Depth normalization: ${(convertTime - inferenceTime).toFixed(1)}ms`);

      // Create ImageData and resize back to original image dimensions
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = depthFloat.width;
      tempCanvas.height = depthFloat.height;
      const tempCtx = tempCanvas.getContext('2d', { willReadFrequently: false });
      const tempImageData = new ImageData(u8Data, depthFloat.width, depthFloat.height);
      tempCtx.putImageData(tempImageData, 0, 0);

      // Resize to original image size
      const outputCanvas = document.createElement('canvas');
      outputCanvas.width = img.width;
      outputCanvas.height = img.height;
      const outputCtx = outputCanvas.getContext('2d', { willReadFrequently: false });
      const useFastResize = Math.abs(img.width - 518) < 50 && Math.abs(img.height - 518) < 50;
      if (useFastResize) {
        outputCtx.imageSmoothingEnabled = false;
      }
      outputCtx.drawImage(tempCanvas, 0, 0, img.width, img.height);

      const result = outputCtx.getImageData(0, 0, img.width, img.height);
      const totalTime = performance.now();
      console.log(`Total AI depth processing: ${(totalTime - startTime).toFixed(1)}ms`);

      return result;
    }

    // Apply LUT transformation to cached raw depth (fast, for parameter changes)
    // This allows real-time adjustment of depth gamma, invert, and depth level without re-running AI
    function applyDepthLUT(rawDepthImageData, nearDepth, farDepth, invertDepth, depthGamma) {
      const width = rawDepthImageData.width;
      const height = rawDepthImageData.height;
      const rawData = rawDepthImageData.data;

      // Create depth LUT
      const depthLUT = makeDepthLUT(nearDepth, farDepth, invertDepth, depthGamma);

      // Apply LUT to grayscale depth
      const result = new ImageData(width, height);
      const resultData = result.data;

      for (let i = 0; i < width * height; i++) {
        const idx = i * 4;
        const alpha = rawData[idx + 3];

        let depth;
        if (alpha < 8) {
          // Transparent pixels always go to background depth
          depth = 0;
        } else {
          // Apply LUT to grayscale value
          const gray = rawData[idx]; // R channel (grayscale)
          depth = depthLUT[gray];
        }

        resultData[idx] = depth;
        resultData[idx + 1] = depth;
        resultData[idx + 2] = depth;
        resultData[idx + 3] = 255; // Full opacity in depth map
      }

      return result;
    }

    // --- Blue-noise loader (tileable PNG), with safe fallback to hash if not ready ---
    const BlueNoise = { img: new Image(), ready: false, data: null, w: 0, h: 0 };
    BlueNoise.img.crossOrigin = 'anonymous';
    BlueNoise.img.src = 'assets/images/blue_noise_256.png';  // put a tileable PNG here (128â€“256 px square)
    
    BlueNoise.img.onload = () => {
      const c = document.createElement('canvas');
      c.width = BlueNoise.img.naturalWidth;
      c.height = BlueNoise.img.naturalHeight;
      const cx = c.getContext('2d');
      cx.drawImage(BlueNoise.img, 0, 0);
      const g = cx.getImageData(0, 0, c.width, c.height);
      BlueNoise.data = g.data;
      BlueNoise.w = c.width;
      BlueNoise.h = c.height;
      BlueNoise.ready = true;
    };
    BlueNoise.img.onerror = () => { BlueNoise.ready = false; }; // fallback to hash

    // Deterministic 32-bit hash -> [0..2^32-1]
    function hash32(n) {
      n = (n ^ 61) ^ (n >>> 16);
      n = n + (n << 3);
      n = n ^ (n >>> 4);
      n = n * 0x27d4eb2d;
      n = n ^ (n >>> 15);
      return n >>> 0;
    }

    // Map 0..255 grayscale -> 0..255 depth using a precomputed LUT
    function makeDepthLUT(nearDepth /*white*/, farDepth /*black*/, invert=false, gamma=1.0) {
      // clamp inputs to 0..255
      nearDepth = Math.max(0, Math.min(255, nearDepth));
      farDepth  = Math.max(0, Math.min(255,  farDepth));
      const lut = new Uint8ClampedArray(256);
    
      for (let g=0; g<256; g++) {
        // normalized grayscale (0=black .. 1=white)
        let t = g / 255;
        // gamma for perceptual control (1.0 = linear)
        if (gamma !== 1) t = Math.pow(t, gamma);
        // optional invert (t -> 1-t)
        if (invert) t = 1 - t;
    
        // linear interpolate between far (black) and near (white)
        const d = farDepth + (nearDepth - farDepth) * t;
        lut[g] = d < 0 ? 0 : d > 255 ? 255 : d|0;
      }
      return lut;
    }

    function makeAutoLevelsLUT(id /*Uint8ClampedArray RGBA*/) {
      let lo = 255, hi = 0;
      for (let i=0; i<id.length; i+=4) {
        const r=id[i], g=id[i+1], b=id[i+2], a=id[i+3];
        if (a < 8) continue;
        const y = (0.2126*r + 0.7152*g + 0.0722*b) | 0;
        if (y < lo) lo = y;
        if (y > hi) hi = y;
      }
      const lut = new Uint8ClampedArray(256);
      const span = Math.max(1, hi - lo);
      for (let v=0; v<256; v++) {
        const t = (v - lo) / span;
        lut[v] = Math.max(0, Math.min(255, (t * 255)|0));
      }
      return lut;
    }

    // DOM Elements
    const previewCanvas = document.getElementById('previewCanvas');
    const ctx = previewCanvas.getContext('2d', { willReadFrequently: true });
    const layerList = document.getElementById('layerList');
    const layerSettings = document.getElementById('layerSettings');

    // Layer management
    const addTextBtn = document.getElementById('addTextBtn');
    const addImageBtn = document.getElementById('addImageBtn');
    const imageFileInput = document.getElementById('imageFileInput');

    // Layer controls
    const textContentGroup = document.getElementById('textContentGroup');
    const fontGroup = document.getElementById('fontGroup');
    const layerText = document.getElementById('layerText');
    const layerFont = document.getElementById('layerFont');
    const customFontInput = document.getElementById('customFontInput');
    const layerSize = document.getElementById('layerSize');
    const layerDepth = document.getElementById('layerDepth');
    const layerRotation = document.getElementById('layerRotation');
    const layerX = document.getElementById('layerX');
    const layerY = document.getElementById('layerY');
    const depthAlgorithmGroup = document.getElementById('depthAlgorithmGroup');
    const layerDepthAlgorithm = document.getElementById('layerDepthAlgorithm');
    const retinexRadiusGroup = document.getElementById('retinexRadiusGroup');
    const layerRetinexRadius = document.getElementById('layerRetinexRadius');
    const depthGammaGroup = document.getElementById('depthGammaGroup');
    const layerDepthGamma = document.getElementById('layerDepthGamma');
    const invertDepthGroup = document.getElementById('invertDepthGroup');
    const invertDepth = document.getElementById('invertDepth');

    // Global controls
    const patternDensity = document.getElementById('patternDensity');
    const stripWidth = document.getElementById('stripWidth');
    const depthScale = document.getElementById('depthScale');
    const outputWidth = document.getElementById('outputWidth');
    const colorScheme = document.getElementById('colorScheme');

    // Actions
    const regenerateBtn = document.getElementById('regenerateBtn');
    const downloadBtn = document.getElementById('downloadBtn');

    // Add Text Layer
    addTextBtn.addEventListener('click', () => {
      const layer = {
        id: nextLayerId++,
        type: 'text',
        text: 'YOUR\nTEXT\nHERE',
        font: "'Arial Black', sans-serif",
        size: 200,
        depth: 15,
        rotation: 0,
        x: state.settings.outputWidth / 2,
        y: state.settings.outputHeight / 4
      };
      state.layers.push(layer);
      updateLayerList();
      selectLayer(layer.id);
      generateAutostereogram();
    });

    // Apply fast box blur approximation of Gaussian blur
    // This is a standard technique: multiple box blur passes approximate Gaussian
    function fastBoxBlur(imageData, radius) {
      const w = imageData.width;
      const h = imageData.height;
      const data = imageData.data;

      // Create temporary buffer for grayscale values
      const gray = new Float32Array(w * h);
      for (let i = 0; i < gray.length; i++) {
        const idx = i * 4;
        gray[i] = 0.2126 * data[idx] + 0.7152 * data[idx + 1] + 0.0722 * data[idx + 2];
      }

      // Apply horizontal box blur
      const temp = new Float32Array(w * h);
      for (let y = 0; y < h; y++) {
        for (let x = 0; x < w; x++) {
          let sum = 0;
          let count = 0;
          for (let dx = -radius; dx <= radius; dx++) {
            const nx = x + dx;
            if (nx >= 0 && nx < w) {
              sum += gray[y * w + nx];
              count++;
            }
          }
          temp[y * w + x] = sum / count;
        }
      }

      // Apply vertical box blur
      const blurred = new Float32Array(w * h);
      for (let y = 0; y < h; y++) {
        for (let x = 0; x < w; x++) {
          let sum = 0;
          let count = 0;
          for (let dy = -radius; dy <= radius; dy++) {
            const ny = y + dy;
            if (ny >= 0 && ny < h) {
              sum += temp[ny * w + x];
              count++;
            }
          }
          blurred[y * w + x] = sum / count;
        }
      }

      return blurred;
    }

    // Process image: convert to grayscale with auto-levels, preserve alpha
    function processImageToGrayscale(img) {
      const canvas = document.createElement('canvas');
      canvas.width = img.width;
      canvas.height = img.height;
      const ctx = canvas.getContext('2d');

      // Draw original image
      ctx.drawImage(img, 0, 0);
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const data = imageData.data;

      // Create auto-levels LUT for this image (only considering non-transparent pixels)
      const autoLUT = makeAutoLevelsLUT(data);

      // Convert to grayscale with auto-levels applied, preserve alpha channel
      for (let i = 0; i < data.length; i += 4) {
        const alpha = data[i + 3];

        // Convert to grayscale using Rec. 709 coefficients
        const gray = Math.floor(0.2126 * data[i] + 0.7152 * data[i + 1] + 0.0722 * data[i + 2]);

        // Apply auto-levels
        const stretched = autoLUT[gray];

        // Store as grayscale, preserving original alpha
        data[i] = stretched;
        data[i + 1] = stretched;
        data[i + 2] = stretched;
        data[i + 3] = alpha; // Preserve original alpha
      }

      ctx.putImageData(imageData, 0, 0);

      // Convert canvas to image
      const processedImg = new Image();
      processedImg.src = canvas.toDataURL();
      return processedImg;
    }

    // Apply shadow-aware processing using Retinex-inspired approach
    //
    // This implementation is based on classic, long-standing academic signal processing techniques:
    // 1. Illumination estimation via large-scale Gaussian blur (pre-1970s technique)
    // 2. Division to extract reflectance/albedo (fundamental to Retinex theory, Land & McCann 1971)
    // 3. Auto-level normalization for optimal contrast (standard histogram stretching)
    //
    // The goal is to separate surface brightness (which should affect depth) from lighting conditions
    // (which should not). This prevents dark shadows from creating false depth holes while preserving
    // genuinely dark objects as distant.
    //
    // This implementation uses only fundamental, unpatented techniques from academic literature.
    // It does NOT implement any specific patented Retinex variants (e.g., MSRCR, MSRCP).
    // The approach follows the original Retinex concept paper:
    // Land, E. H., & McCann, J. J. (1971). "Lightness and retinex theory."
    // Journal of the Optical Society of America, 61(1), 1-11.
    //
    function applyShadowAwareDepth(imageData, radius) {
      const w = imageData.width;
      const h = imageData.height;
      const data = imageData.data;

      // Step 1: Estimate illumination using large-scale blur
      // This approximates the lighting field without capturing fine detail
      const illumination = fastBoxBlur(imageData, radius);

      // Step 2: Calculate reflectance (albedo) by dividing by illumination
      // Add small epsilon to avoid division by zero
      const epsilon = 1.0;
      const reflectance = new Uint8ClampedArray(w * h);

      for (let i = 0; i < w * h; i++) {
        const idx = i * 4;
        const gray = 0.2126 * data[idx] + 0.7152 * data[idx + 1] + 0.0722 * data[idx + 2];
        const illum = illumination[i] + epsilon;

        // Normalize reflectance to 0-255 range
        // This separates surface brightness from lighting
        const refl = Math.min(255, (gray / illum) * 128);
        reflectance[i] = refl;
      }

      // Step 3: Apply auto-levels to reflectance for better depth range
      // Create temporary RGBA data for autolevels function, preserving alpha
      const tempData = new Uint8ClampedArray(w * h * 4);
      for (let i = 0; i < w * h; i++) {
        const idx = i * 4;
        tempData[idx] = reflectance[i];
        tempData[idx + 1] = reflectance[i];
        tempData[idx + 2] = reflectance[i];
        tempData[idx + 3] = data[idx + 3]; // Preserve original alpha
      }
      const autoLUT = makeAutoLevelsLUT(tempData);

      // Step 4: Apply auto-levels and store result, preserving alpha
      for (let i = 0; i < w * h; i++) {
        const stretched = autoLUT[reflectance[i]];
        const idx = i * 4;
        const alpha = data[idx + 3];
        data[idx] = stretched;
        data[idx + 1] = stretched;
        data[idx + 2] = stretched;
        data[idx + 3] = alpha; // Preserve original alpha
      }

      return imageData;
    }

    // Add Image Layer
    addImageBtn.addEventListener('click', () => {
      imageFileInput.click();
    });

    imageFileInput.addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      const img = new Image();
      img.onload = () => {
        const layer = {
          id: nextLayerId++,
          type: 'image',
          originalImage: img,
          image: img, // Will be processed
          size: 50, // Multiplied by 4 internally = 200px actual
          depth: 20,
          rotation: 0,
          x: state.settings.outputWidth / 2,
          y: state.settings.outputHeight / 2,
          depthAlgorithm: 'depth-anything-v2',
          retinexRadius: 32,
          invertDepth: false,
          depthGamma: 1.0
        };

        // Process the image to grayscale with auto-levels
        layer.image = processImageToGrayscale(img);

        state.layers.push(layer);
        updateLayerList();
        selectLayer(layer.id);

        // Wait for processed image to load before generating
        layer.image.onload = () => generateAutostereogram();
      };
      img.src = URL.createObjectURL(file);
      imageFileInput.value = '';
    });

    // Custom Font Upload
    customFontInput.addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      const fontName = 'CustomFont_' + Date.now();
      const arrayBuffer = await file.arrayBuffer();
      const fontFace = new FontFace(fontName, arrayBuffer);
      await fontFace.load();
      document.fonts.add(fontFace);

      state.customFonts.set(fontName, fontName);

      const activeLayer = getActiveLayer();
      if (activeLayer && activeLayer.type === 'text') {
        activeLayer.font = fontName;
        generateAutostereogram();
      }

      customFontInput.value = '';
    });

    layerFont.addEventListener('change', (e) => {
      if (e.target.value === 'custom') {
        customFontInput.click();
      } else {
        const activeLayer = getActiveLayer();
        if (activeLayer && activeLayer.type === 'text') {
          activeLayer.font = e.target.value;
          generateAutostereogram();
        }
      }
    });

    // Layer Settings Event Listeners
    layerText.addEventListener('input', () => {
      const activeLayer = getActiveLayer();
      if (activeLayer && activeLayer.type === 'text') {
        activeLayer.text = layerText.value;
        updateLayerList();
        generateAutostereogram();
      }
    });

    layerSize.addEventListener('input', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer) {
        activeLayer.size = parseInt(e.target.value);
        document.getElementById('layerSizeValue').textContent = e.target.value;
        generateAutostereogram();
      }
    });

    layerDepthAlgorithm.addEventListener('change', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer && activeLayer.type === 'image') {
        activeLayer.depthAlgorithm = e.target.value;
        // Show/hide retinex radius based on algorithm
        retinexRadiusGroup.style.display = e.target.value === 'retinex' ? 'block' : 'none';
        // Invalidate cache when algorithm changes (will re-run on next generation)
        // Note: cache check in generateDepthMap will handle this, but explicit delete is cleaner
        depthCache.delete(activeLayer.id);
        generateAutostereogram();
      }
    });

    layerRetinexRadius.addEventListener('input', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer && activeLayer.type === 'image') {
        activeLayer.retinexRadius = parseInt(e.target.value);
        document.getElementById('layerRetinexRadiusValue').textContent = e.target.value + 'px';
        generateAutostereogram();
      }
    });

    layerDepthGamma.addEventListener('input', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer && activeLayer.type === 'image') {
        activeLayer.depthGamma = parseFloat(e.target.value);
        document.getElementById('layerDepthGammaValue').textContent = e.target.value;
        generateAutostereogram();
      }
    });

    invertDepth.addEventListener('change', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer && activeLayer.type === 'image') {
        activeLayer.invertDepth = e.target.checked;
        generateAutostereogram();
      }
    });

    layerDepth.addEventListener('input', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer) {
        activeLayer.depth = parseInt(e.target.value);
        document.getElementById('layerDepthValue').textContent = e.target.value;
        generateAutostereogram();
      }
    });

    layerRotation.addEventListener('input', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer) {
        activeLayer.rotation = parseInt(e.target.value);
        document.getElementById('layerRotationValue').textContent = e.target.value + 'Â°';
        generateAutostereogram();
      }
    });

    layerX.addEventListener('input', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer) {
        activeLayer.x = parseInt(e.target.value);
        document.getElementById('layerXValue').textContent = e.target.value;
        generateAutostereogram();
      }
    });

    layerY.addEventListener('input', (e) => {
      const activeLayer = getActiveLayer();
      if (activeLayer) {
        activeLayer.y = parseInt(e.target.value);
        document.getElementById('layerYValue').textContent = e.target.value;
        generateAutostereogram();
      }
    });

    // Global Settings Event Listeners
    patternDensity.addEventListener('input', (e) => {
      state.settings.patternDensity = parseInt(e.target.value);
      document.getElementById('patternDensityValue').textContent = e.target.value;
      generateAutostereogram();
    });

    stripWidth.addEventListener('input', (e) => {
      state.settings.stripWidth = parseInt(e.target.value);
      document.getElementById('stripWidthValue').textContent = e.target.value + 'px';
      generateAutostereogram();
    });

    depthScale.addEventListener('input', (e) => {
      state.settings.depthScale = parseFloat(e.target.value);
      document.getElementById('depthScaleValue').textContent = e.target.value;
      generateAutostereogram();
    });

    outputWidth.addEventListener('input', (e) => {
      state.settings.outputWidth = parseInt(e.target.value);
      state.settings.outputHeight = Math.round(state.settings.outputWidth * 2 / 3);
      document.getElementById('outputWidthValue').textContent = e.target.value + 'px';

      previewCanvas.width = state.settings.outputWidth;
      previewCanvas.height = state.settings.outputHeight;

      // Update position sliders max values
      layerX.max = state.settings.outputWidth;
      layerY.max = state.settings.outputHeight;

      generateAutostereogram();
    });

    colorScheme.addEventListener('change', (e) => {
      state.settings.colorScheme = e.target.value;
      generateAutostereogram();
    });

    regenerateBtn.addEventListener('click', () => {
      generateAutostereogram();
    });

    downloadBtn.addEventListener('click', () => {
      const link = document.createElement('a');
      link.download = 'apoculus-3d-image.png';
      link.href = previewCanvas.toDataURL();
      link.click();
    });

    // License modal
    document.getElementById('licenseFooter').addEventListener('click', () => {
      document.getElementById('licenseModal').classList.add('show');
      document.getElementById('licenseOverlay').classList.add('show');
    });

    const closeLicense = () => {
      document.getElementById('licenseModal').classList.remove('show');
      document.getElementById('licenseOverlay').classList.remove('show');
    };

    document.getElementById('licenseClose').addEventListener('click', closeLicense);
    document.getElementById('licenseOverlay').addEventListener('click', closeLicense);

    // Help modal
    document.getElementById('imageDepthHelpLink').addEventListener('click', () => {
      document.getElementById('depthHelpModal').classList.add('show');
      document.getElementById('depthHelpOverlay').classList.add('show');
    });

    const closeDepthHelp = () => {
      document.getElementById('depthHelpModal').classList.remove('show');
      document.getElementById('depthHelpOverlay').classList.remove('show');
    };

    document.getElementById('depthHelpClose').addEventListener('click', closeDepthHelp);
    document.getElementById('depthHelpOverlay').addEventListener('click', closeDepthHelp);

    // Helper Functions
    function getActiveLayer() {
      return state.layers.find(l => l.id === state.activeLayerId);
    }

    function selectLayer(id) {
      state.activeLayerId = id;
      const layer = getActiveLayer();

      if (!layer) {
        layerSettings.style.display = 'none';
        return;
      }

      layerSettings.style.display = 'block';

      // Show/hide appropriate controls
      if (layer.type === 'text') {
        textContentGroup.style.display = 'block';
        fontGroup.style.display = 'block';
        depthAlgorithmGroup.style.display = 'none';
        retinexRadiusGroup.style.display = 'none';
        depthGammaGroup.style.display = 'none';
        invertDepthGroup.style.display = 'none';
        layerText.value = layer.text;
        layerFont.value = layer.font;
      } else {
        textContentGroup.style.display = 'none';
        fontGroup.style.display = 'none';
        depthAlgorithmGroup.style.display = 'block';
        depthGammaGroup.style.display = 'block';
        invertDepthGroup.style.display = 'block';

        layerDepthAlgorithm.value = layer.depthAlgorithm || 'direct';
        layerRetinexRadius.value = layer.retinexRadius || 32;
        document.getElementById('layerRetinexRadiusValue').textContent = (layer.retinexRadius || 32) + 'px';

        // Show/hide retinex radius based on algorithm
        retinexRadiusGroup.style.display = (layer.depthAlgorithm === 'retinex') ? 'block' : 'none';

        layerDepthGamma.value = layer.depthGamma || 1.0;
        document.getElementById('layerDepthGammaValue').textContent = (layer.depthGamma || 1.0).toFixed(2);
        invertDepth.checked = layer.invertDepth || false;
      }

      // Update controls
      layerSize.value = layer.size;
      layerDepth.value = layer.depth;
      layerRotation.value = layer.rotation;
      layerX.value = layer.x;
      layerY.value = layer.y;

      document.getElementById('layerSizeValue').textContent = layer.size;
      document.getElementById('layerDepthValue').textContent = layer.depth;
      document.getElementById('layerRotationValue').textContent = layer.rotation + 'Â°';
      document.getElementById('layerXValue').textContent = layer.x;
      document.getElementById('layerYValue').textContent = layer.y;

      updateLayerList();
    }

    function deleteLayer(id) {
      const index = state.layers.findIndex(l => l.id === id);
      if (index !== -1) {
        state.layers.splice(index, 1);
        // Invalidate depth cache for deleted layer
        depthCache.delete(id);
        if (state.activeLayerId === id) {
          state.activeLayerId = state.layers.length > 0 ? state.layers[0].id : null;
        }
        updateLayerList();
        if (state.activeLayerId) {
          selectLayer(state.activeLayerId);
        } else {
          layerSettings.style.display = 'none';
        }
        generateAutostereogram();
      }
    }

    function updateLayerList() {
      if (state.layers.length === 0) {
        layerList.innerHTML = `
          <div class="help-text" style="font-size: 0.85rem; padding: 15px;">
            No layers yet. Add text or an image to begin.
          </div>
        `;
        return;
      }

      layerList.innerHTML = state.layers.map(layer => {
        const isActive = layer.id === state.activeLayerId;
        const name = layer.type === 'text'
          ? (layer.text.substring(0, 20) + (layer.text.length > 20 ? '...' : ''))
          : 'Image';
        const details = `Depth: ${layer.depth} | Size: ${layer.size}`;

        return `
          <div class="layer-item ${isActive ? 'active' : ''}" data-id="${layer.id}">
            <div class="layer-info">
              <div class="layer-name">${name}</div>
              <div class="layer-details">${details}</div>
            </div>
            <button class="layer-delete" data-id="${layer.id}">Delete</button>
          </div>
        `;
      }).join('');

      // Add event listeners
      layerList.querySelectorAll('.layer-item').forEach(item => {
        item.addEventListener('click', (e) => {
          if (!e.target.classList.contains('layer-delete')) {
            selectLayer(parseInt(item.dataset.id));
          }
        });
      });

      layerList.querySelectorAll('.layer-delete').forEach(btn => {
        btn.addEventListener('click', (e) => {
          e.stopPropagation();
          deleteLayer(parseInt(btn.dataset.id));
        });
      });
    }

    // Generate Depth Map from Layers
    async function generateDepthMap() {
      const width = state.settings.outputWidth;
      const height = state.settings.outputHeight;

      // Create temporary canvas for depth map
      const depthCanvas = document.createElement('canvas');
      depthCanvas.width = width;
      depthCanvas.height = height;
      const depthCtx = depthCanvas.getContext('2d');

      // Fill with background depth (0 = farthest)
      depthCtx.fillStyle = '#000000';
      depthCtx.fillRect(0, 0, width, height);

      // Render each layer sorted by depth (farthest first)
      const sortedLayers = [...state.layers].sort((a, b) => a.depth - b.depth);

      for (const layer of sortedLayers) {
        depthCtx.save();
        depthCtx.translate(layer.x, layer.y);
        depthCtx.rotate((layer.rotation * Math.PI) / 180);

        // Calculate depth color (0-255 based on depth 0-100)
        const depthColor = Math.floor((layer.depth / 100) * 255);
        depthCtx.fillStyle = `rgb(${depthColor}, ${depthColor}, ${depthColor})`;

        if (layer.type === 'text') {
          depthCtx.font = `bold ${layer.size}px ${layer.font}`;
          depthCtx.textAlign = 'center';
          depthCtx.textBaseline = 'middle';
          //depthCtx.fillText(layer.text, 0, 0);

          // Allow literal "\n" in a single-line input OR real newlines from a textarea
          const text = (layer.text || '').replace(/\\n/g, '\n');
          const lines = text.split(/\r?\n/);
        
          const lineHeight = 1.1 * layer.size;
          for (let i = 0; i < lines.length; i++) {
            const t = lines[i];
            const dy = i * lineHeight;
            depthCtx.fillText(t, 0, dy);
          }
        } else if (layer.type === 'image') {
          const aspectRatio = layer.image.width / layer.image.height;
          // Scale images 4x larger for better visibility
          const scaledSize = layer.size * 4;
          const drawWidth = scaledSize * aspectRatio;
          const drawHeight = scaledSize;

          // Draw image to temp canvas
          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = drawWidth;
          tempCanvas.height = drawHeight;
          const tempCtx = tempCanvas.getContext('2d');
          tempCtx.drawImage(layer.image, 0, 0, drawWidth, drawHeight);

          // Get image data for processing
          let imgData = tempCtx.getImageData(0, 0, drawWidth, drawHeight);

          // Apply selected depth algorithm with caching
          if (layer.depthAlgorithm === 'depth-anything-v2') {
            // Check cache first
            const cacheEntry = depthCache.get(layer.id);
            let rawDepth;

            if (cacheEntry && cacheEntry.algorithm === 'depth-anything-v2') {
              // Cache hit! Use cached raw depth (no AI inference needed)
              rawDepth = cacheEntry.rawDepth;
              console.log(`Using cached depth for layer ${layer.id}`);
            } else {
              // Cache miss or algorithm changed - run AI model
              try {
                console.log(`Running AI depth prediction for layer ${layer.id}`);
                rawDepth = await applyDepthAnythingV2Raw(layer.originalImage);
                // Cache the raw depth for future use
                depthCache.set(layer.id, {
                  rawDepth: rawDepth,
                  algorithm: 'depth-anything-v2'
                });
              } catch (error) {
                console.error('Depth Anything V2 failed, falling back to grayscale:', error);
                // Fallback to grayscale if model fails - don't cache failures
              }
            }

            if (rawDepth) {
              // Apply LUT transformation (fast, parameter-dependent)
              const nearDepth = (layer.depth / 100) * 255;
              const farDepth = 0;
              imgData = applyDepthLUT(rawDepth, nearDepth, farDepth, layer.invertDepth, layer.depthGamma);

              // Resize to target dimensions
              const resizeCanvas = document.createElement('canvas');
              resizeCanvas.width = drawWidth;
              resizeCanvas.height = drawHeight;
              const resizeCtx = resizeCanvas.getContext('2d');
              const tempImgCanvas = document.createElement('canvas');
              tempImgCanvas.width = imgData.width;
              tempImgCanvas.height = imgData.height;
              const tempImgCtx = tempImgCanvas.getContext('2d');
              tempImgCtx.putImageData(imgData, 0, 0);
              resizeCtx.drawImage(tempImgCanvas, 0, 0, drawWidth, drawHeight);
              imgData = resizeCtx.getImageData(0, 0, drawWidth, drawHeight);
            }
          } else if (layer.depthAlgorithm === 'retinex') {
            // Apply shadow-aware processing using Retinex-inspired approach
            // Scale radius proportionally to image size
            const scaleFactor = Math.sqrt((drawWidth * drawHeight) / (1200 * 800));
            const scaledRadius = Math.round(layer.retinexRadius * scaleFactor);
            imgData = applyShadowAwareDepth(imgData, scaledRadius);
          }
          // For 'direct' algorithm, image is already processed (grayscale with auto-levels)

          // Apply depth LUT (depth-anything-v2 already applied LUT in its cache path)
          if (layer.depthAlgorithm !== 'depth-anything-v2') {
            // Create depth LUT for this layer
            // nearDepth = layer depth (white pixels), farDepth = 0 (black pixels)
            const nearDepth = (layer.depth / 100) * 255;
            const farDepth = 0;
            const depthLUT = makeDepthLUT(nearDepth, farDepth, layer.invertDepth, layer.depthGamma);

            // Map grayscale values to depth using LUT
            // Transparent pixels always map to depth 0 (background), regardless of invert
            for (let i = 0; i < imgData.data.length; i += 4) {
              const alpha = imgData.data[i + 3];

              let depth;
              if (alpha < 8) {
                // Transparent pixels always go to background depth
                depth = 0;
              } else {
                // Image is grayscale, so R=G=B
                const gray = imgData.data[i];
                depth = depthLUT[gray];
              }

              imgData.data[i] = depth;
              imgData.data[i + 1] = depth;
              imgData.data[i + 2] = depth;
              imgData.data[i + 3] = 255; // Full opacity in depth map
            }
          }
          tempCtx.putImageData(imgData, 0, 0);

          depthCtx.drawImage(tempCanvas, -drawWidth / 2, -drawHeight / 2);
        }

        depthCtx.restore();
      }

      // Apply blur for soft edges (reduce sparkle)
      //depthCtx.filter = 'blur(2px)';
      //depthCtx.drawImage(depthCanvas, 0, 0);
      //depthCtx.filter = 'none';

      // Get depth map data
      const imageData = depthCtx.getImageData(0, 0, width, height);
      const depthMap = new Uint8Array(width * height);

      for (let i = 0; i < depthMap.length; i++) {
        depthMap[i] = imageData.data[i * 4]; // Use red channel
      }

      return depthMap;
    }

    // Simple hash function for pseudo-random per-pixel values
    function hashPixel(x, y, seed) {
      let h = seed + x * 374761393 + y * 668265263;
      h = (h ^ (h >>> 13)) * 1274126177;
      return (h ^ (h >>> 16)) >>> 0;
    }

    // Convert hash to [0,1) float
    function hashToFloat(hash) {
      return (hash & 0xFFFFFF) / 0x1000000;
    }

    // Generate Random Dot Pattern Strip
    function generatePatternStrip(width, height, density, colorScheme) {
      const stripCanvas = document.createElement('canvas');
      stripCanvas.width = width;
      stripCanvas.height = height;
      const stripCtx = stripCanvas.getContext('2d');

      const imageData = stripCtx.createImageData(width, height);
      const data = imageData.data;

      // Random seed for this generation
      const seed = Math.floor(Math.random() * 0xFFFFFFFF);

      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const i = (y * width + x) * 4;

//          // Use hash-based random for better distribution
//          const hash1 = hashPixel(x, y, seed);
//          const hash2 = hashPixel(x, y, seed + 1);
//          const hash3 = hashPixel(x, y, seed + 2);
//
//          const rand1 = hashToFloat(hash1);
//          const rand2 = hashToFloat(hash2);
//          const rand3 = hashToFloat(hash3);
//
//          // Determine if this pixel is "on" (higher density = more dots)
//          const threshold = density / 10;
//          const isOn = rand1 < threshold;

          // Use hash-based random for color variation (keep these)
          const hash2 = hashPixel(x, y, seed + 1);
          const hash3 = hashPixel(x, y, seed + 2);
          
          const rand2 = hashToFloat(hash2);
          const rand3 = hashToFloat(hash3);
          
          // Determine if this pixel is "on" (higher density = more dots)
          const threshold = Math.min(1, Math.max(0, density / 10)); // clamp 0..1
          
          let isOn;
          if (BlueNoise.ready) {
            // Sample tileable blue-noise (red channel 0..255)
            const bx = x % BlueNoise.w;
            const by = y % BlueNoise.h;
            const bi = (by * BlueNoise.w + bx) * 4;
            const val = BlueNoise.data[bi]; // 0..255
            isOn = val < threshold * 255;
          } else {
            // Fallback: original white-noise hash
            const hash1 = hashPixel(x, y, seed);
            const rand1 = hashToFloat(hash1);
            isOn = rand1 < threshold;
          }


          let r, g, b;

          if (colorScheme === 'grayscale') {
            const brightness = isOn ? Math.floor(rand2 * 255) : 0;
            r = g = b = brightness;
          } else if (colorScheme === 'color') {
            r = isOn ? Math.floor(rand1 * 255) : 0;
            g = isOn ? Math.floor(rand2 * 255) : 0;
            b = isOn ? Math.floor(rand3 * 255) : 0;
          } else if (colorScheme === 'cyan') {
            const brightness = isOn ? Math.floor(rand2 * 255) : 0;
            r = 0;
            g = brightness;
            b = brightness;
          } else if (colorScheme === 'magenta') {
            const brightness = isOn ? Math.floor(rand2 * 255) : 0;
            r = brightness;
            g = 0;
            b = brightness;
          } else if (colorScheme === 'green') {
            const brightness = isOn ? Math.floor(rand2 * 255) : 0;
            r = 0;
            g = brightness;
            b = 0;
          } else if (colorScheme === 'amber') {
            const brightness = isOn ? Math.floor(rand2 * 255) : 0;
            r = brightness;
            g = Math.floor(brightness * 0.75);
            b = 0;
          } else if (colorScheme === 'rainbow') {
            if (isOn) {
              const hue = rand2 * 360;
              const sat = 0.8;
              const light = 0.5;
              const rgb = hslToRgb(hue, sat, light);
              r = rgb[0];
              g = rgb[1];
              b = rgb[2];
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'neon') {
            if (isOn) {
              const choice = Math.floor(rand2 * 5);
              if (choice === 0) { r = 255; g = 0; b = 255; } // Magenta
              else if (choice === 1) { r = 0; g = 255; b = 255; } // Cyan
              else if (choice === 2) { r = 255; g = 255; b = 0; } // Yellow
              else if (choice === 3) { r = 0; g = 255; b = 0; } // Green
              else { r = 255; g = 0; b = 128; } // Hot pink
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'fire') {
            if (isOn) {
              const intensity = rand2;
              r = 255;
              g = Math.floor(intensity * 165); // 0-165
              b = Math.floor(intensity * intensity * 100); // 0-100
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'ice') {
            if (isOn) {
              const intensity = rand2;
              r = Math.floor(intensity * 200 + 55); // 55-255
              g = Math.floor(intensity * 255); // 0-255
              b = 255;
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'forest') {
            if (isOn) {
              const intensity = rand2;
              r = Math.floor(intensity * 100); // 0-100
              g = Math.floor(intensity * 180 + 75); // 75-255
              b = Math.floor(intensity * 80); // 0-80
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'sunset') {
            if (isOn) {
              const choice = rand2;
              if (choice < 0.33) {
                r = 255; g = Math.floor(rand3 * 100); b = Math.floor(rand3 * 150 + 100); // Purple
              } else if (choice < 0.66) {
                r = 255; g = Math.floor(rand3 * 150 + 100); b = Math.floor(rand3 * 100); // Orange
              } else {
                r = 255; g = Math.floor(rand3 * 100 + 100); b = Math.floor(rand3 * 180 + 75); // Pink
              }
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'ocean') {
            if (isOn) {
              const depth = rand2;
              r = Math.floor(depth * 100); // 0-100
              g = Math.floor(depth * 200 + 55); // 55-255
              b = Math.floor(depth * 100 + 155); // 155-255
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'matrix') {
            if (isOn) {
              const brightness = Math.floor(rand2 * 200 + 55); // 55-255
              r = 0;
              g = brightness;
              b = Math.floor(brightness * 0.3); // Slight blue tint
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'vaporwave') {
            if (isOn) {
              const choice = rand2 < 0.5;
              if (choice) {
                r = 255; g = Math.floor(rand3 * 100 + 100); b = 255; // Pink
              } else {
                r = Math.floor(rand3 * 100); g = Math.floor(rand3 * 200 + 55); b = 255; // Cyan
              }
            } else {
              r = g = b = 0;
            }
          } else if (colorScheme === 'synthwave') {
            if (isOn) {
              const choice = Math.floor(rand2 * 3);
              if (choice === 0) {
                r = Math.floor(rand3 * 100 + 155); g = 0; b = 255; // Purple
              } else if (choice === 1) {
                r = 255; g = Math.floor(rand3 * 100); b = Math.floor(rand3 * 180 + 75); // Pink
              } else {
                r = 0; g = Math.floor(rand3 * 200 + 55); b = 255; // Cyan
              }
            } else {
              r = g = b = 0;
            }
          } else {
            r = g = b = 0;
          }

          data[i] = r;
          data[i + 1] = g;
          data[i + 2] = b;
          data[i + 3] = 255;
        }
      }

      stripCtx.putImageData(imageData, 0, 0);
      return stripCanvas;
    }

    // HSL to RGB conversion for rainbow mode
    function hslToRgb(h, s, l) {
      h = h / 360;
      const q = l < 0.5 ? l * (1 + s) : l + s - l * s;
      const p = 2 * l - q;

      const hueToRgb = (p, q, t) => {
        if (t < 0) t += 1;
        if (t > 1) t -= 1;
        if (t < 1/6) return p + (q - p) * 6 * t;
        if (t < 1/2) return q;
        if (t < 2/3) return p + (q - p) * (2/3 - t) * 6;
        return p;
      };

      return [
        Math.floor(hueToRgb(p, q, h + 1/3) * 255),
        Math.floor(hueToRgb(p, q, h) * 255),
        Math.floor(hueToRgb(p, q, h - 1/3) * 255)
      ];
    }

    // Generate Autostereogram
    async function generateAutostereogram() {
      if (state.layers.length === 0) {
        ctx.fillStyle = '#000';
        ctx.fillRect(0, 0, previewCanvas.width, previewCanvas.height);
        return;
      }

      const width  = state.settings.outputWidth;
      const height = state.settings.outputHeight;
      const stripW = state.settings.stripWidth;
      const MIN_SEP = 8; // don't let separation collapse; tweak 8â€“12 if needed

      // Small constants/utilities for symmetry & visibility
      const OCC_THRESH = 2; // tolerate tiny depth noise (0â€“255 scale)

      // Reflection padding index (periodic mirror): 0..W-1, W..2W-2 -> mirror back, etc.
      function mirrorIndex(i, w) {
        const period = 2 * w - 2;
        if (period <= 0) return 0;
        let m = ((i % period) + period) % period;
        return m < w ? m : period - m;
      }


      // Clamp disparity so separation âˆˆ [MIN_SEP, stripW]
      const rawMaxDisp = Math.floor(stripW * state.settings.depthScale);
      const maxDisp    = Math.min(rawMaxDisp, stripW - MIN_SEP);

      // Depth map (0..255, where brighter = nearer)
      const depthMap = await generateDepthMap();
    
      // Base pattern strip (width = stripW, tiled across each row)
      const patternStrip = generatePatternStrip(
        stripW,
        height,
        state.settings.patternDensity,
        state.settings.colorScheme
      );
      const stripData = patternStrip.getContext('2d').getImageData(0, 0, stripW, height);
    
      // Output
      const outputData = ctx.createImageData(width, height);
      const out = outputData.data;
    
      // Small union-find helper with path compression
      function findRoot(parent, i) {
        while (parent[i] !== i) {
          parent[i] = parent[parent[i]];
          i = parent[i];
        }
        return i;
      }
    
      // Row-wise phase offsets to break horizontal stratification
      const rowShift = new Uint16Array(height);
      const shiftSeed = (Math.random() * 0xFFFFFFFF) >>> 0; // new every generation
      for (let y = 0; y < height; y++) {
        rowShift[y] = hash32(shiftSeed ^ y) % stripW;
      }

      for (let y = 0; y < height; y++) {
        const row = y * width;
        const parent = new Int32Array(width);
        for (let x = 0; x < width; x++) parent[x] = x;
    
        // 1) Link pixel pairs for this scanline
        for (let x = 0; x < width; x++) {
          const z = depthMap[row + x] / 255;                // 0..1
          const disp = Math.round(z * maxDisp);
          const sep  = Math.max(MIN_SEP, stripW - disp);    // safe separation
    
          //const left  = x - Math.floor(sep / 2);
          // centered pairing around x
          const dither = (sep & 1) && (y & 1) ? 1 : 0;   // alternate the half-pixel
          const left   = Math.floor(x - (sep + dither)/2);

          const right = left + sep;
    
          if (left >= 0 && right < width) {
            // Prefer the nearer surface at this pair position
            const dl = depthMap[row + left];
            const dr = depthMap[row + right];
    
            let L = findRoot(parent, left);
            let R = findRoot(parent, right);
//            if (L !== R) {
//              if (dl >= dr) parent[R] = L; else parent[L] = R;
//            }
            if (L !== R) {
              if (dl > dr) {
                parent[R] = L;
              } else if (dr > dl) {
                parent[L] = R;
              } else {
                // equal depth: alternate by checkerboard to avoid directional bias
                if (((x ^ y) & 1) === 0) parent[R] = L; else parent[L] = R;
              }
            }

          }
        }
    
        // 2a) Compute a centered phase per connected component (removes left-anchoring)
        const comp = new Map(); // root -> {min,max}
        for (let x = 0; x < width; x++) {
          const r = findRoot(parent, x);
          const o = comp.get(r);
          if (o) {
            if (x < o.min) o.min = x;
            if (x > o.max) o.max = x;
          } else {
            comp.set(r, { min: x, max: x });
          }
        }
        const phaseByRoot = new Map();
        for (const [r, o] of comp) {
          const center = Math.round((o.min + o.max) / 2) % stripW;
          phaseByRoot.set(r, center);
        }

        // 2) Paint: one color per set, sampled by the set rootâ€™s phase
        const colorByRoot = new Map();
        for (let x = 0; x < width; x++) {
          const root = findRoot(parent, x);
          let color = colorByRoot.get(root);
          if (!color) {
//            const stripX = root % stripW;                   // IMPORTANT: use root, not x
          //  const stripX = phaseByRoot.get(root);
            const stripX = (phaseByRoot.get(root) + rowShift[y]) % stripW;

            const si = (y * stripW + stripX) * 4;
            color = [
              stripData.data[si],
              stripData.data[si + 1],
              stripData.data[si + 2],
              255
            ];
            colorByRoot.set(root, color);
          }
    
          const oi = (row + x) * 4;
          out[oi]     = color[0];
          out[oi + 1] = color[1];
          out[oi + 2] = color[2];
          out[oi + 3] = 255;
        }
      }
    
      ctx.putImageData(outputData, 0, 0);
    }


    // Initialize
    generateAutostereogram();

    // Preload Depth Anything V2 model in background (if available)
    // This improves UX by having the model ready when user adds first image
    setTimeout(() => {
      loadDepthModel().catch(err => {
        console.log('Model preload skipped (model file not found - see models/README.md)');
      });
    }, 1000); // Delay 1 second to let UI render first
  </script>
</body>
</html>
